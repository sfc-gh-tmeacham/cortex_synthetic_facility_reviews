{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "a63vclfspw3dyj4brfkp",
   "authorId": "272264884048",
   "authorName": "TOM",
   "authorEmail": "tom.meacham@snowflake.com",
   "sessionId": "8f66463e-54d9-4501-afc5-ff2b91e1f899",
   "lastEditTime": 1742569335496
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a2013a-5cb8-4ae1-8469-360048187a7d",
   "metadata": {
    "name": "README_MD",
    "collapsed": false,
    "resultHeight": 1864
   },
   "source": "# Healthcare Facility Reviews Analysis with Snowflake Cortex\n\nThis Snowflake notebook demonstrates the use of Snowflake's Cortex Generative AI functions to analyze healthcare facility reviews. The notebook showcases various AI-powered text analysis capabilities including sentiment analysis, text classification, summarization, and translation.\n\n## Key Features\n\n- Creates synthetic healthcare facility reviews using Cortex COMPLETE function\n- Analyzes review sentiment using SENTIMENT function\n- Generates summaries of reviews with SUMMARIZE function\n- Classifies reviews by topic using CLASSIFY_TEXT function\n- Translates reviews to other languages using TRANSLATE function\n- Provides detailed recommendations based on negative reviews\n- Visualizes sentiment analysis results using Streamlit\n\n## Setup Requirements\n\n- Snowflake database and schema for storing tables\n- Streamlit for visualization components\n- Python packages: pandas, plotly\n\n## Main Components\n\n1. **Data Generation**\n   - Creates 1,000 synthetic healthcare facility reviews with `mistral-large2`\n   - Uses Zipf distribution to simulate realistic data patterns\n\n2. **Text Analysis**\n   - Sentiment scoring (-1 to 1 scale)\n   - Topic classification across 9 healthcare-specific categories\n   - Review summarization\n   - Translation capability\n\n3. **Advanced Analysis**\n   - Detailed recommendations for negative reviews\n   - Analysis of sentiment patterns by topic\n   - Visualization of sentiment distribution\n   - Interactive dashboards using Streamlit\n\n4. **Visualization**\n   - Positive vs. negative review distribution by topic\n   - Average sentiment scores\n   - Review count by topic\n   - Key metrics and detailed topic analysis\n\n## Functions Used\n\n- `snowflake.cortex.complete`\n- `snowflake.cortex.sentiment`\n- `snowflake.cortex.classify_text`\n- `snowflake.cortex.summarize`\n- `snowflake.cortex.translate`\n\n## Tables Created\n\n1. `FACILITY_REVIEWS`: Raw synthetic review data\n2. `FACILITY_REVIEWS_ENRICHED`: Reviews enriched with AI analysis\n\n## Usage Notes\n\n- Initial setup may take ~5 minutes for synthetic data generation\n- Uses `mistral-large2` for initial dataset setup\n- Uses `mixtral-8x7b` model for detailed analysis\n- Not all models are available in every Snowflake region. However you can gain access to them by enabling [Cross-Region Inference](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cross-region-inference) on your Snowflake account. (ACCOUNTADMIN role required)\n- Includes custom display functions for better visualization\n- Supports interactive filtering and analysis of review data\n\n"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "imports_py",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "# Important: Import 'plotly' from the packages menu (used at the end of the notebook)\n\n# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4f2e14a4-403a-4b2c-9ea3-729eace2fd81",
   "metadata": {
    "name": "INFO_MD",
    "collapsed": false,
    "resultHeight": 386
   },
   "source": "### Task-specific functions\nTask-specific functions are purpose-built and managed functions that automate routine tasks, like simple summaries and quick translations, that donâ€™t require any customization. Snowflake Cortex features are provided as **SQL functions** and are also **available in Python**. \n\n\n\n- `CLASSIFY_TEXT`: Given a piece of text, classifies it into one of the categories that you define.\n- `EXTRACT_ANSWER`: Given a question and unstructured data, returns the answer to the question if it can be found in the data.\n- `PARSE_DOCUMENT`: Given an internal or external stage with documents, returns an object that contains a JSON-formatted string with extracted text content using OCR mode, or the extracted text and layout elements using LAYOUT mode.\n- `SENTIMENT`: Returns a sentiment score, from -1 to 1, representing the detected positive or negative sentiment of the given text.\n- `SUMMARIZE`: Returns a summary of the given text.\n- `TRANSLATE`: Translates given text from any supported language to any other.\n- `EMBED_TEXT_768`: Given a piece of text, returns a vector embedding of 768 dimensions that represents that text.\n- `EMBED_TEXT_1024`: Given a piece of text, returns a vector embedding of 1024 dimensions that represents that text."
  },
  {
   "cell_type": "code",
   "id": "fae743a4-17fd-462d-bfaf-4bf7d4b49b99",
   "metadata": {
    "language": "sql",
    "name": "setup_sql",
    "collapsed": false,
    "resultHeight": 87
   },
   "outputs": [],
   "source": "-- compatibility \n-- USE ROLE ACCOUNTADMIN;\n-- ALTER ACCOUNT SET CORTEX_ENABLED_CROSS_REGION = 'AWS_US';\n\n-- set your role and database\nSET my_role = 'SYSADMIN';\nSET my_db = 'DEMO_HC_FACILITY_REVIEWS';\n\n-- use whatever database and schema you like, the rest of the notbook does not use fully qualified identifiers.\nUSE ROLE IDENTIFIER($my_role);\nCREATE DATABASE IF NOT EXISTS IDENTIFIER($my_db)\n    COMMENT = 'Storage and analysis of healthcare facility reviews using Snowflake Cortex AI capabilities';\nUSE DATABASE IDENTIFIER($my_db);\nUSE SCHEMA PUBLIC;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2e616503-7c06-4be3-8d94-4a3e158fb822",
   "metadata": {
    "name": "DEFINE_DISPLY_FUNCTIONS_MD",
    "collapsed": false,
    "resultHeight": 113
   },
   "source": "### Note \nThe code in the cell below defines some custom python display functions used later in the notebook. You can choose 'collapsed' from the cell display menu, since we don't need to see this code. "
  },
  {
   "cell_type": "code",
   "id": "12dbec41-f4d0-4633-8f77-d65b464e6883",
   "metadata": {
    "language": "python",
    "name": "define_pretty_print_functions_py",
    "collapsed": false,
    "resultHeight": 0,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "# These functions are used later in the notebook but we can define them here. feel free to collapse this cell.\ndef display_column(df, column_name='REVIEW', title=None):\n    \"\"\"\n    Display all entries from a specified column in a DataFrame using Streamlit components,\n    including character count for each entry.\n    \n    Parameters:\n    df (pandas.DataFrame): DataFrame containing the data\n    column_name (str): Name of the column to display (default: 'REVIEW')\n    title (str): Title to display above the content. If None, uses column name\n    \"\"\"\n    # Check if specified column exists\n    if column_name not in df.columns:\n        st.error(f\"Error: DataFrame must contain a '{column_name}' column\")\n        return\n    \n    # Use column name as title if none provided\n    if title is None:\n        title = column_name.title()\n    \n    # Add a title\n    st.header(title)\n    \n    # Display each entry in a card-like container\n    for idx, entry in enumerate(df[column_name], 1):\n        with st.container():\n            st.markdown(f\"##### {column_name} #{idx}\")\n            st.write(entry)\n            st.metric(\"Characters\", len(str(entry)))\n            st.markdown(\"---\")\n\ndef display_dual_columns(df, column1_name, column2_name, title=None):\n    \"\"\"\n    Display entries from two columns side by side in a DataFrame using Streamlit components,\n    including character count for each entry.\n    \n    Parameters:\n    df (pandas.DataFrame): DataFrame containing the data\n    column1_name (str): Name of the first column to display\n    column2_name (str): Name of the second column to display\n    title (str): Title to display above the content\n    \"\"\"\n    # Check if specified columns exist\n    for col in [column1_name, column2_name]:\n        if col not in df.columns:\n            st.error(f\"Error: DataFrame must contain a '{col}' column\")\n            return\n    \n    # Add title if provided\n    if title:\n        st.header(title)\n    \n    # Display entries side by side\n    for idx in range(len(df)):\n        col1, col2 = st.columns(2)\n        \n        # Left column\n        with col1:\n            st.markdown(f\"##### {column1_name} #{idx + 1}\")\n            st.write(df[column1_name].iloc[idx])\n            st.metric(\"Characters\", len(str(df[column1_name].iloc[idx])))\n            \n        # Right column\n        with col2:\n            st.markdown(f\"##### {column2_name} #{idx + 1}\")\n            st.write(df[column2_name].iloc[idx])\n            st.metric(\"Characters\", len(str(df[column2_name].iloc[idx])))\n        \n        st.markdown(\"---\")\n\ndef display_text_and_metric(df, text_column, metric_column, title=None):\n    \"\"\"\n    Display entries where first column is text and second column is a numeric metric,\n    colored red for negative values and green for positive values.\n    \n    Parameters:\n    df (pandas.DataFrame): DataFrame containing the data\n    text_column (str): Name of the column containing text\n    metric_column (str): Name of the column containing numeric values\n    title (str): Title to display above the content\n    \"\"\"\n    # Check if specified columns exist\n    for col in [text_column, metric_column]:\n        if col not in df.columns:\n            st.error(f\"Error: DataFrame must contain a '{col}' column\")\n            return\n    \n    # Verify metric column contains numeric values\n    if not pd.to_numeric(df[metric_column], errors='coerce').notna().all():\n        st.error(f\"Error: Column '{metric_column}' must contain numeric values\")\n        return\n    \n    # Add title if provided\n    if title:\n        st.header(title)\n    \n    # Display entries side by side\n    for idx in range(len(df)):\n        col1, col2 = st.columns(2)\n        \n        # Text column\n        with col1:\n            st.markdown(f\"##### {text_column} #{idx + 1}\")\n            st.write(df[text_column].iloc[idx])\n            st.metric(\"Characters\", len(str(df[text_column].iloc[idx])))\n            \n        # Metric column with color based on value\n        with col2:\n            value = float(df[metric_column].iloc[idx])\n            st.markdown(f\"##### {metric_column} #{idx + 1}\")\n            if value > 0:\n                st.markdown(f'<p style=\"color:rgb(9, 171, 59); font-size:40px; font-weight:bold\">{value}</p>', unsafe_allow_html=True)\n            elif value < 0:\n                st.markdown(f'<p style=\"color:rgb(255, 43, 43); font-size:40px; font-weight:bold\">{value}</p>', unsafe_allow_html=True)\n            else:\n                st.markdown(f'<p style=\"font-size:40px; font-weight:bold\">{value}</p>', unsafe_allow_html=True)\n        \n        st.markdown(\"---\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ad2af55-0211-4fad-a4e1-1136caf5f710",
   "metadata": {
    "name": "CREATE_DATASET_MD",
    "collapsed": false,
    "resultHeight": 358
   },
   "source": "# One time setup\n## Let's use the Cortex COMPLETE function to generate synthetic Healthcare Facility Reviews\nThis will create a table with 1,000 synthetic reviews. This only needs to be run once, and may take a few minutes (~5) the first time.\n\n\n### :bulb: Did you know?\nSnowflake's `ZIPF` function generates random numbers that follow Zipf's law - a pattern where the frequency of any item is inversely proportional to its rank. In real life, Zipf's law appears in things like word usage (the most common word appears twice as often as the second most common, three times as often as the third, etc.). \n\nTo generate the synthetic reviews, we leverage this to randomize parameters, but take control of the *distrubution* of them. \n"
  },
  {
   "cell_type": "code",
   "id": "b06d964b-3165-4815-9e60-bbfd05d23573",
   "metadata": {
    "language": "sql",
    "name": "create_synthetic_reviews_sql",
    "collapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "-- this may take a few minutes the first time you run it. ~5 min\n\n-- choose your model, the model MUST be a constant and cannot be sourced from a column reference.\nSET complete_model = 'mistral-large2';\n\nCREATE TABLE IF NOT EXISTS FACILITY_REVIEWS \n-- CREATE OR REPLACE TABLE FACILITY_REVIEWS\nAS (\n\n-- Config \nWITH _seed as (\nSELECT \n    row_number() over (order by null) as review_id,\n    zipf(1,5, random()) as sentiment_seed,\n    zipf(1,3, random()) as complexity_seed,\n    zipf(1,4, random()) as visit_type_seed,\n    zipf(1,9, random()) as core_topic_seed,\n    decode(sentiment_seed,\n            1, 'positive',\n            2, 'neutral',\n            3, 'negative',\n            4, 'very negative',\n            5, 'very positive') as sentiment,\n    decode(complexity_seed,\n            1, 'basic',\n            2, 'moderate',\n            3, 'detailed') as complexity,\n    decode(visit_type_seed,\n            1, 'routine',\n            2, 'procedure',\n            3, 'specialist',\n            4, 'emergency') as visit_type,\n    decode(core_topic_seed,\n            1, 'Wait times: Time spent waiting for appointments and in-office care',\n            2, 'Staff interactions: How personnel treat and engage with patients',\n            3, 'Medical care quality: Effectiveness and competence of treatment',\n            4, 'Facility conditions: Building cleanliness and maintenance',\n            5, 'Administrative processes: Efficiency of paperwork and procedures',\n            6, 'Communication: Clarity and completeness of information sharing',\n            7, 'Billing/insurance: Handling of payments and claims',\n            8, 'Follow-up care: Post-treatment support and monitoring',\n            9, 'Food quality: Quality and variety of cafeteria or vending options') as core_topic,            \nFROM table(generator(rowcount => 1000))\n)\n-- Output\nSELECT\n    review_id,\n    sentiment,\n    complexity,\n    visit_type,\n    core_topic,\n$$\n# SYSTEM CONTEXT\nYou are an advanced testing tool designed for generating diverse, coherent patient reviews.\n\n# INPUT PARAMETERS\nreview_config: {\n    sentiment: $$ || sentiment || $$,\n    visit_type: $$ || visit_type || $$,\n    complexity: $$ || complexity || $$,\n    core_topic: $$ || core_topic || $$,\n}\n\n# OUTPUT SPECIFICATION\n- Generate ONLY the text string of the patient review based on the review_config INPUT PARAMETERS\n- Review should be between 5 and 30 setences\n\n# CONSTRAINTS\n- Keep medical scenarios realistic but generic\n- Include natural language patterns\n- Avoid specific names, locations, or identifiable details\n- Generate clinically plausible scenarios\n- Do not use the word \"overall\"\n- Do not start or end the response with '\"'\n\nReturn only the review, no additional text or explanations.\n$$ as prompt_string,\n    object_construct('role', 'user',\n                     'content', prompt_string) as prompt_object,\n    array_construct(prompt_object) as complete_prompt,\n    snowflake.cortex.complete($complete_model, complete_prompt, {'temperature': 1.0}) as cortex_reponse,\n    trim(cortex_reponse:choices[0]:messages::string) as review,\n    cortex_reponse:usage:model::varchar(100) as model,\n    cortex_reponse:usage:completion_tokens::int as completion_tokens,\n    cortex_reponse:usage:prompt_tokens::int as prompt_tokens,\n    cortex_reponse:usage:total_tokens::int as total_tokens,\n    cortex_reponse:created::timestamp_ntz as created_utc_ts,\nFROM _seed);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb4c341e-8eb2-4e23-92d4-4a168864c829",
   "metadata": {
    "language": "sql",
    "name": "sample_reviews_sql",
    "collapsed": false,
    "resultHeight": 427,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "SELECT \n    REVIEW_ID,\n    REVIEW,\nFROM FACILITY_REVIEWS\nSAMPLE (10 ROWS);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b8854933-97fa-48b0-bc3e-77bc36483db4",
   "metadata": {
    "name": "SENTIMENT_MD",
    "collapsed": false,
    "resultHeight": 143
   },
   "source": "## SENTIMENT\nThe SENTIMENT function returns sentiment as a score between -1 to 1 \n\nWith -1 being the most negative and 1 the most positive, with values around 0 neutral) for the given English-language input text."
  },
  {
   "cell_type": "code",
   "id": "524f4826-59a3-4e39-b218-4f9936d6fbf4",
   "metadata": {
    "language": "sql",
    "name": "sample_sentiment_sql",
    "collapsed": false,
    "resultHeight": 217
   },
   "outputs": [],
   "source": "-- random sample of positive and negative reviews\nSELECT \n    REVIEW_ID,\n    REVIEW,\n    SNOWFLAKE.CORTEX.SENTIMENT(REVIEW) as SENTIMENT_SCORE,\nFROM FACILITY_REVIEWS\nSAMPLE (2 ROWS)\nWHERE SENTIMENT_SCORE > 0\nUNION ALL\nSELECT \n    REVIEW_ID,\n    REVIEW,\n    SNOWFLAKE.CORTEX.SENTIMENT(REVIEW) as SENTIMENT_SCORE,\nFROM FACILITY_REVIEWS\nSAMPLE (2 ROWS)\nWHERE SENTIMENT_SCORE < 0;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b4878f18-62f9-4c5e-88b4-854b2f44b281",
   "metadata": {
    "language": "python",
    "name": "pretty_print_sentiment_py",
    "collapsed": false,
    "resultHeight": 2497
   },
   "outputs": [],
   "source": "setntiment_df = cells.sample_sentiment_sql.to_pandas()\n\ndisplay_text_and_metric(setntiment_df, 'REVIEW', 'SENTIMENT_SCORE', title=\"Reviews\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4d12e2d5-002e-4c26-a5f1-417269a87e95",
   "metadata": {
    "name": "SUMMARY_MD",
    "collapsed": false,
    "resultHeight": 102
   },
   "source": "## SUMMARIZE\nThe `SUMMARIZE` function returns a summary of the given English text."
  },
  {
   "cell_type": "code",
   "id": "04a83c7c-64dd-450d-9a0a-4360b7b324a5",
   "metadata": {
    "language": "sql",
    "name": "sample_summary_sql",
    "collapsed": false,
    "resultHeight": 182
   },
   "outputs": [],
   "source": "SELECT \n    REVIEW_ID,\n    REVIEW,\n    SNOWFLAKE.CORTEX.SUMMARIZE(REVIEW) as SUMMARY,\nFROM FACILITY_REVIEWS\nSAMPLE (3 ROWS);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4112f018-b16b-4c28-87a5-95171482ab36",
   "metadata": {
    "language": "python",
    "name": "pretty_print_summary_py",
    "collapsed": false,
    "resultHeight": 2364
   },
   "outputs": [],
   "source": "summary_df = cells.sample_summary_sql.to_pandas()\n\ndisplay_dual_columns(summary_df, 'REVIEW', 'SUMMARY', 'Review and Summary')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "08fe53d6-86e6-4039-8bab-d26468f83b2f",
   "metadata": {
    "name": "CLASSIFY_TEXT_MD",
    "collapsed": false,
    "resultHeight": 102
   },
   "source": "## CLASSIFY_TEXT\nThe `CLASSIFY_TEXT` function classifies free-form text into categories that you provide. The text may be a plain English string."
  },
  {
   "cell_type": "code",
   "id": "2058ff22-0fa2-4a91-9a5a-af2564d2b179",
   "metadata": {
    "language": "sql",
    "name": "sample_classify_reivews_sql",
    "collapsed": false,
    "resultHeight": 427
   },
   "outputs": [],
   "source": "SELECT \n    REVIEW_ID,\n    REVIEW,\n    SNOWFLAKE.CORTEX.CLASSIFY_TEXT(\n        REVIEW,\n        [\n            {'label': 'Wait times',\n             'description': 'Time spent waiting for appointments and in-office care'\n            },\n            {'label': 'Staff interactions',\n             'description': 'How personnel treat and engage with patients'\n            },\n            {'label': 'Medical care quality',\n             'description': 'Effectiveness and competence of treatment'\n            },\n            {'label': 'Facility conditions',\n             'description': 'Building cleanliness and maintenance'\n            },\n            {'label': 'Administrative processes',\n             'description': 'Efficiency of paperwork and procedures'\n            },\n            {'label': 'Communication',\n             'description': 'Clarity and completeness of information sharing'\n            },\n            {'label': 'Billing/insurance',\n             'description': 'Handling of payments and claims'\n            },\n            {'label': 'Follow-up care',\n             'description': 'Post-treatment support and monitoring'\n            },\n            {'label': 'Food quality',\n             'description': 'Quality and variety of cafeteria or vending options'\n            }\n        ],\n            {'task_description': 'Return a classification of the primary topic of the review'}\n        ):label::string as topic_classification\nFROM FACILITY_REVIEWS\nSAMPLE (10 ROWS);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f22b683b-f706-43af-b7ba-d3c33e59ba36",
   "metadata": {
    "name": "TRANSLATE_MD",
    "collapsed": false,
    "resultHeight": 102
   },
   "source": "## TRANSLATE\nThe `TRANSLATE` function translates text from the indicated or detected source language to a target language."
  },
  {
   "cell_type": "code",
   "id": "254cb219-84fe-4264-84f2-060ef6bc00cd",
   "metadata": {
    "language": "sql",
    "name": "sample_translate_sql",
    "collapsed": false,
    "resultHeight": 147
   },
   "outputs": [],
   "source": "SELECT \n    REVIEW_ID,\n    REVIEW,\n    SNOWFLAKE.CORTEX.TRANSLATE(REVIEW,'en','fr') as REVIEW_TRANSLATED,\nFROM FACILITY_REVIEWS\nSAMPLE (2 ROWS);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "38dc1011-5492-4dce-a690-21df2c59c1e8",
   "metadata": {
    "language": "python",
    "name": "pretty_print_translation_py",
    "collapsed": false,
    "resultHeight": 1584
   },
   "outputs": [],
   "source": "translate_df = cells.sample_translate_sql.to_pandas()\n\ndisplay_dual_columns(translate_df, 'REVIEW', 'REVIEW_TRANSLATED', 'Review and Spanish Translation')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2acda4ba-7c1a-44cd-bf27-588ec06acd72",
   "metadata": {
    "name": "CREATE_ENRICHED_TABLE_MD",
    "collapsed": false,
    "resultHeight": 89
   },
   "source": "## Let's tie together by creating a new table of our reviews, enriched with with data from Cortex LLM functions!"
  },
  {
   "cell_type": "code",
   "id": "8bb3f083-77de-4d7b-b88f-c692094212fd",
   "metadata": {
    "language": "sql",
    "name": "create_enriched_review_table_sql",
    "resultHeight": 112,
    "collapsed": false
   },
   "outputs": [],
   "source": "CREATE TABLE IF NOT EXISTS FACILITY_REVIEWS_ENRICHED \n-- CREATE OR REPLACE TABLE FACILITY_REVIEWS_ENRICHED \nAS (\nSELECT \n    REVIEW_ID,\n    REVIEW,\n    SNOWFLAKE.CORTEX.SUMMARIZE(REVIEW) as SUMMARY,\n    SNOWFLAKE.CORTEX.SENTIMENT(REVIEW) as SENTIMENT_SCORE,\n    SNOWFLAKE.CORTEX.CLASSIFY_TEXT(\n        REVIEW,\n        [\n            {'label': 'Wait times',\n             'description': 'Time spent waiting for appointments and in-office care'\n            },\n            {'label': 'Staff interactions',\n             'description': 'How personnel treat and engage with patients'\n            },\n            {'label': 'Medical care quality',\n             'description': 'Effectiveness and competence of treatment'\n            },\n            {'label': 'Facility conditions',\n             'description': 'Building cleanliness and maintenance'\n            },\n            {'label': 'Administrative processes',\n             'description': 'Efficiency of paperwork and procedures'\n            },\n            {'label': 'Communication',\n             'description': 'Clarity and completeness of information sharing'\n            },\n            {'label': 'Billing/insurance',\n             'description': 'Handling of payments and claims'\n            },\n            {'label': 'Follow-up care',\n             'description': 'Post-treatment support and monitoring'\n            },\n            {'label': 'Food quality',\n             'description': 'Quality and variety of cafeteria or vending options'\n            }\n        ],\n            {'task_description': 'Return a classification of the primary topic of the review'}\n        ):label::string as topic_classification\nFROM FACILITY_REVIEWS\n);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e1d86f87-45b4-4ebb-8cce-1584b9f17485",
   "metadata": {
    "name": "EXAMPLE_COMPLETE_MD",
    "collapsed": false,
    "resultHeight": 227
   },
   "source": "## Define Prompt\n\nLet's create a prompt to analyse a review, and identify key issues and provide recomendations for remediation.\n\n*Note: In a real world use case, you would not likely do this for each individual reivew, but rather over the all reviews in a time frame.*\n\nFor an example see this video:\n- [How To Analyze Support Tickets With Snowflake Cortex LLMs, Notebooks, And Streamlit](https://www.youtube.com/watch?v=tpKqZO7kTf8)"
  },
  {
   "cell_type": "code",
   "id": "71676be2-cbfe-41a2-bd9a-b2cce2df32e3",
   "metadata": {
    "language": "python",
    "name": "recommendation_prompt_py",
    "collapsed": false,
    "resultHeight": 0,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "recommendation_prompt = \"\"\"$$\nYou are a healthcare facility operations consultant specializing in patient experience optimization. Your task is to analyze patient reviews and provide actionable recommendations for facility owners.\n\nWhen analyzing a review, follow these steps:\n\n1. First, carefully identify explicit and implicit pain points in the patient's review. Consider:\n   - Wait times\n   - Staff interactions\n   - Facility conditions\n   - Communication issues\n   - Administrative processes\n   - Medical care quality\n   - Follow-up care\n   - Billing and insurance handling\n\n2. For each identified issue:\n   - Assess its severity\n   - Consider its potential impact on other patients\n   - Evaluate how it affects the facility's reputation\n   - Determine if it presents any regulatory or compliance risks\n\n3. Generate specific, actionable recommendations that:\n   - Address the root cause of each issue\n   - Can be implemented within 3-6 months\n   - Consider resource constraints\n   - Align with healthcare regulations\n   - Prioritize patient safety and satisfaction\n\nFormat your response as follows:\n\n# Key Issues Identified\n- [List the main problems identified in the review]\n\n# Priority Recommendations\n1. [First recommendation]\n   - Expected impact\n   - Required resources\n\n2. [Second recommendation]\n   - Expected impact\n   - Required resources\n\n[Continue with additional recommendations]\n\n# Quick Wins\n- [List 2-3 immediate actions that can be taken within 1 week]\n\n# Long-term Considerations\n- [List any systemic issues that need strategic planning]\n\nGuidelines for recommendations:\n- Be specific and actionable\n- Include estimated implementation costs when relevant\n- Consider staff training needs\n- Factor in regulatory compliance\n- Focus on sustainable solutions\n- Prioritize based on impact vs. effort\n\nRemember to:\n- Maintain a professional, solution-focused tone\n- Consider both patient and staff perspectives\n- Include measurable outcomes\n- Suggest monitoring mechanisms for implemented changes\n\nExample Review:\n\"Had to wait 2 hours to see the doctor. The reception staff were rude and didn't acknowledge me when I checked in. The facility was clean but outdated. The doctor was great once I saw them, but getting any follow-up information has been impossible. Leaving messages but no one calls back.\"\n\nExample Response:\n\n# Key Issues Identified\n- Excessive wait times\n- Poor front desk customer service\n- Communication breakdown in follow-up care\n- Outdated facility appearance\n\n# Priority Recommendations\n1. Implement digital queue management system\n   - Impact: 40% reduction in wait times\n   - Resources: Software system, staff training\n\n2. Customer service training program for front desk staff\n   - Impact: Improved patient satisfaction scores\n   - Resources: External trainer, weekly sessions\n\n3. Establish dedicated follow-up care coordinator\n   - Impact: 24-hour response guarantee\n   - Resources: New hire, communication protocols\n\n# Quick Wins\n- Install self-check-in kiosk\n- Create standardized follow-up call schedule\n- Post visible wait time estimates\n\n# Long-term Considerations\n- Facility modernization plan\n- Staff retention strategy\n- Patient communication system upgrade\n\nPlease analyze the provided review and generate recommendations following this format.\n\n## REVIEW\n\n$$\n\"\"\"",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "080578d3-ee17-4483-8db7-96c543f0ad95",
   "metadata": {
    "name": "GET_RECOMMENDATIONS_MD",
    "collapsed": false,
    "resultHeight": 46
   },
   "source": "### With our prompt crafted, let's have Cortex analyse our some of reviews with the most negative sentiment."
  },
  {
   "cell_type": "code",
   "id": "1cb28487-4358-410f-b8dd-d876aecd4a6f",
   "metadata": {
    "language": "sql",
    "name": "recommendation_sql",
    "collapsed": false,
    "resultHeight": 147
   },
   "outputs": [],
   "source": "SELECT \n    REVIEW_ID,\n    REVIEW,\n    SENTIMENT_SCORE,\n    SNOWFLAKE.CORTEX.COMPLETE(\n        'claude-3-5-sonnet',\n        CONCAT(\n            {{recommendation_prompt}}, \n            REVIEW\n            )\n        ) as recommendations\nFROM FACILITY_REVIEWS_ENRICHED\nSAMPLE (2 rows)\nWHERE SENTIMENT_SCORE < -0.5;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c6256a0f-fa3b-4c9a-bd3b-f890d551a838",
   "metadata": {
    "language": "python",
    "name": "pretty_print_recomendations_py",
    "collapsed": false,
    "resultHeight": 2461,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "recommendation_df = cells.recommendation_sql.to_pandas()\n\ndisplay_dual_columns(recommendation_df, 'REVIEW', 'RECOMMENDATIONS', 'Negative Reviews and Recommendations')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "332b8dfb-356d-4139-92be-33b77b12d1a3",
   "metadata": {
    "name": "ANALYSE_MD",
    "collapsed": false,
    "resultHeight": 134
   },
   "source": "## Let's see the results of Cortex in action for a sentiment analysis use case\n\n* First will will see how an analyst can use the new extracted attributes to filter the review data set\n* Then we will see how we can use these attrubutes to perform analysis over the entire data set.\n\n"
  },
  {
   "cell_type": "code",
   "id": "8b4f160e-1616-4bcf-8068-971443689e49",
   "metadata": {
    "language": "sql",
    "name": "filter_negative_commnication_reviews_sql",
    "collapsed": false,
    "resultHeight": 217
   },
   "outputs": [],
   "source": "-- filter by Communication Issues with a Sentiment Score of less than -.05\nSELECT\n    *\nFROM FACILITY_REVIEWS_ENRICHED\nWHERE TRUE\n    AND topic_classification = 'Communication'\n    AND sentiment_score < -0.5;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "648a4ee4-8aa4-4312-b9e1-9f409efbf4aa",
   "metadata": {
    "language": "sql",
    "name": "example_analysis_sql",
    "collapsed": false,
    "resultHeight": 392
   },
   "outputs": [],
   "source": "SELECT \n    topic_classification,\n    count(topic_classification) as topic_count,\n    (count_if(sentiment_score > 0)/topic_count * 100)::decimal(8,2) as prct_positive,\n    (count_if(sentiment_score < 0)/topic_count * 100)::decimal(8,4) as prct_negative,\n    min(sentiment_score)::decimal(8,4)*100 as min_sentiment_score,\n    max(sentiment_score)::decimal(8,4)*100 as max_sentiment_score,\n    avg(sentiment_score)::decimal(8,4)*100 as avg_sentiment_score,\n    array_agg(sentiment_score*100) as sentiment_scores\nFROM FACILITY_REVIEWS_ENRICHED\ngroup by all;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c0dd4f03-8b9c-45ad-be04-900bd7c13db5",
   "metadata": {
    "name": "VISUALIZE_SENTIMENT_MD",
    "collapsed": false,
    "resultHeight": 102
   },
   "source": "## Since Snowflake Notebooks have Streamlit built-in, we can visulize the results! :sparkles:\nFor the cell below, choose 'results only' for the cell display menu so the python code to make the chart is distracting."
  },
  {
   "cell_type": "code",
   "id": "09aaad02-947d-47b3-90c5-95f94e35d40b",
   "metadata": {
    "language": "python",
    "name": "visualize_analysis_py",
    "collapsed": false,
    "resultHeight": 1691,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "import streamlit as st\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\ndef create_sentiment_visualization(df):\n    \"\"\"\n    Create a sentiment analysis visualization using Streamlit and Plotly.\n    \n    Parameters:\n    df: pandas DataFrame with columns:\n        - TOPIC_CLASSIFICATION\n        - TOPIC_COUNT\n        - PRCT_POSITIVE\n        - PRCT_NEGATIVE\n        - AVG_SENTIMENT_SCORE\n    \"\"\"\n    # Sort DataFrame by negative percentage for first chart\n    df_neg_sorted = df.sort_values('PRCT_NEGATIVE', ascending=False)\n    \n    # Sort DataFrame by count for the count chart\n    df_count_sorted = df.sort_values('TOPIC_COUNT', ascending=False)\n    \n    fig = make_subplots(\n        rows=3, cols=1,\n        subplot_titles=(\"Positive vs Negative Reviews by Topic\", \n                       \"Average Sentiment Score by Topic\",\n                       \"Number of Reviews by Topic\"),\n        row_heights=[0.4, 0.3, 0.3],\n        vertical_spacing=0.1\n    )\n    \n    # Add bars for positive percentages\n    fig.add_trace(\n        go.Bar(\n            name=\"Positive\",\n            x=df_neg_sorted['TOPIC_CLASSIFICATION'],\n            y=df_neg_sorted['PRCT_POSITIVE'],\n            marker_color='#2ecc71',\n            text=df_neg_sorted['PRCT_POSITIVE'].round(1).astype(str) + '%',\n            textposition='auto',\n        ),\n        row=1, col=1\n    )\n    \n    # Add bars for negative percentages\n    fig.add_trace(\n        go.Bar(\n            name=\"Negative\",\n            x=df_neg_sorted['TOPIC_CLASSIFICATION'],\n            y=df_neg_sorted['PRCT_NEGATIVE'],\n            marker_color='#e74c3c',\n            text=df_neg_sorted['PRCT_NEGATIVE'].round(1).astype(str) + '%',\n            textposition='auto',\n        ),\n        row=1, col=1\n    )\n    \n    # Add average sentiment score bar chart\n    fig.add_trace(\n        go.Bar(\n            name=\"Average Sentiment\",\n            x=df_neg_sorted['TOPIC_CLASSIFICATION'],\n            y=df_neg_sorted['AVG_SENTIMENT_SCORE'],\n            marker_color='#3498db',\n            text=df_neg_sorted['AVG_SENTIMENT_SCORE'].round(2).astype(str),\n            textposition='auto',\n        ),\n        row=2, col=1\n    )\n    \n    # Add review count bar chart\n    fig.add_trace(\n        go.Bar(\n            name=\"Review Count\",\n            x=df_count_sorted['TOPIC_CLASSIFICATION'],\n            y=df_count_sorted['TOPIC_COUNT'],\n            marker_color='#9b59b6',\n            text=df_count_sorted['TOPIC_COUNT'].astype(str),\n            textposition='auto',\n        ),\n        row=3, col=1\n    )\n    \n    # Update layout\n    fig.update_layout(\n        barmode='group',\n        height=1000,\n        showlegend=True,\n        yaxis_title=\"Percentage of Reviews\",\n        yaxis2_title=\"Average Sentiment Score\",\n        yaxis3_title=\"Number of Reviews\"\n    )\n    \n    # Display the plot\n    st.plotly_chart(fig, use_container_width=True)\n    \n    # Display additional metrics\n    st.subheader(\"Detailed Topic Analysis\")\n    \n    # Create four columns for metrics\n    cols = st.columns(4)\n    \n    # Calculate metrics\n    best_topic = df.loc[df['PRCT_POSITIVE'].idxmax(), 'TOPIC_CLASSIFICATION']\n    highest_positive = df['PRCT_POSITIVE'].max()\n    worst_topic = df.loc[df['PRCT_NEGATIVE'].idxmax(), 'TOPIC_CLASSIFICATION']\n    highest_negative = df['PRCT_NEGATIVE'].max()\n    best_avg = df.loc[df['AVG_SENTIMENT_SCORE'].idxmax(), 'TOPIC_CLASSIFICATION']\n    highest_avg = df['AVG_SENTIMENT_SCORE'].max()\n    most_reviewed = df.loc[df['TOPIC_COUNT'].idxmax(), 'TOPIC_CLASSIFICATION']\n    highest_count = df['TOPIC_COUNT'].max()\n    \n    # Display metrics\n    with cols[0]:\n        st.metric(\n            \"Most Positive Topic\",\n            best_topic,\n            f\"{highest_positive:.1f}% Positive\"\n        )\n    \n    with cols[1]:\n        st.metric(\n            \"Most Negative Topic\",\n            worst_topic,\n            f\"{highest_negative:.1f}% Negative\"\n        )\n    \n    with cols[2]:\n        st.metric(\n            \"Highest Average Sentiment\",\n            best_avg,\n            f\"{highest_avg:.2f}\"\n        )\n    \n    with cols[3]:\n        st.metric(\n            \"Most Reviewed Topic\",\n            most_reviewed,\n            f\"{highest_count} reviews\"\n        )\n    \n    # Display raw data in an expandable section\n    with st.expander(\"View Raw Data\"):\n        st.dataframe(df)\n\n# Display Results\nanalysis_df = cells.example_analysis_sql.to_pandas()\nst.title(\"Facility Reviews Sentiment Analysis\")\ncreate_sentiment_visualization(analysis_df)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8c451749-c11d-4dd2-b234-f8375eaecdbd",
   "metadata": {
    "name": "COMPLETE_MD",
    "collapsed": false,
    "resultHeight": 631
   },
   "source": "# COMPLETE\n\nGiven a prompt, the instruction-following `COMPLETE` function generates a response using your choice of language model. In the simplest use case, the prompt is a single string. \n\nYou may also provide a conversation including multiple prompts and responses for interactive chat-style usage, and in this form of the function you can also specify hyperparameter options to customize the style and size of the output. \n\nIn order to implement safeguards, you can also enable the Cortex Guard parameter that filters potentially unsafe and harmful responses from a LLM.\n\nAt the time of this writing, The `COMPLETE` function supports the following models. More models are added added over time. Different models can have different costs:\n\n#### [Currently Available Models](https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex#arguments)\n"
  },
  {
   "cell_type": "markdown",
   "id": "0f176584-1de7-4184-b37b-4e69223904df",
   "metadata": {
    "name": "FINAL_REPORT_MD",
    "collapsed": false
   },
   "source": "## We can also use Cortex to create a report based on the above data. \nFor this use case, we will leverage the Python API for Cortex as opposed to SQL"
  },
  {
   "cell_type": "code",
   "id": "c629c2d2-8d9f-482b-8a10-d7538a6d271c",
   "metadata": {
    "language": "python",
    "name": "final_report_py",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# import complete from the snowflake-python-ml package\nfrom snowflake.cortex import complete\n\n# reference the previous SQL result\ndf = cells.example_analysis_sql.to_pandas()\n# remove array of scores\ndf = df.drop('SENTIMENT_SCORES', axis=1)\n\n# craft prompt for the llm\nprompt = '''\nAnalyze this healthcare facility sentiment dataset containing pre-calculated average scores per topic (scale: [-100-100]) and:\n\n1. **Score Benchmarking**\n   - Compare each topic's score to:\n     * Industry benchmarks ([specify if available])\n     * Ideal performance thresholds ([Y])\n   - Flag topics where:\n     * Score < [threshold1] (critical)\n     * Score between [threshold1] and [threshold2] (needs improvement)\n     * Score > [threshold2] (success)\n\n3. **Topic Interdependencies**\n   - Perform quadrant analysis:\n     Y-axis: Topic importance (predefined or frequency)\n     X-axis: Current performance score\n   - Identify:\n     * High importance/Low performance (Urgent focus)\n     * High importance/High performance (Maintain)\n     * Low importance/High performance (Optimize resources)\n     * Low importance/Low performance (Deprioritize)\n\n4. Output should be plain language with recomendations\n\n5. Do not provide followup questions to the user. \n\n6. Output should be in markdown format with headers, subheaders, and bulletpoints.\n\n'''\n\n# We will provide a prompt and the aggregated dataset from above\nanalysis_explain = complete('claude-3-5-sonnet', f'{prompt}: {df}')\n\n#display report\nst.markdown(analysis_explain)",
   "execution_count": null
  }
 ]
}